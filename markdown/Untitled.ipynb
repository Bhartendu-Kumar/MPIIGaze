{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "<head>\n",
    "  <h2>Background Image</h2>\n",
    "    <style=\"background-image:url('gazeview.jpg'); background-size: cover; min-height: 500px; background-attachment: fixed; background-position: right top; background-repeat:no-repeat;\"> \n",
    "    </style>\n",
    "-->\n",
    "<body>\n",
    "<div class=\"background\" style=\"background-image:url('gazeview.jpg'); background-size: cover; min-height: 500px; background-attachment: fixed; background-position: right top; background-repeat:no-repeat;\"> \n",
    "\n",
    "<!--\n",
    "<head>\n",
    "<link href=\"format.css\" type=\"text/css\" rel=\"stylesheet\" />    \n",
    "</head>    \n",
    "-->   \n",
    "\n",
    "<!--\n",
    "<style>\n",
    "body{\n",
    "background-image:url('gazeview.jpg'); \n",
    "  background-size: cover; \n",
    "  min-height: 500px; \n",
    "  background-attachment: fixed; \n",
    "  background-position: right top; \n",
    "  background-repeat:no-repeat;    \n",
    "}\n",
    "-->     \n",
    "   \n",
    "## Σκοπός Ειδικού Θέματος\n",
    "\n",
    "Πειραματική εξέταση του Αλγορίθμου __Random Forests__ στο πρόβλημα του Gaze Recognition\n",
    "\n",
    "\n",
    "\n",
    "## Δεδομένα\n",
    "\n",
    "* Ως δεδομένα επέλεξα το <a href=\"https://www.mpi-inf.mpg.de/de/abteilungen/computer-vision-and-multimodal-computing/research/gaze-based-human-computer-interaction/appearance-based-gaze-estimation-in-the-wild-mpiigaze/\"\n",
    "target=\"_blank\">MPIIGaze Dataset</a> [^3]. Ωστόσο υπάρχουν κι'άλλα dataset, όπως το <a href=\"https://www.idiap.ch/dataset/eyediap\" target=\"_blank\">Eyediap</a> και το <a href=\"http://www.hci.iis.u-tokyo.ac.jp/datasets/\" target=\"_blank\">Multiview Dataset</a> [^2].\n",
    "\n",
    "\n",
    "* Οι αρχικές εικόνες έχουνε κανονικοποιηθεί με τέτοιο τρόπο, ώστε να εξετάζονται όλες οι εικόνες υπό τις __ίδιες συνθήκες__ .Επίσης κάθε μάτι εξετάζεται __ανεξάρτητα__ από το άλλο.\n",
    "\n",
    "\n",
    "* Τα δεδομένα που έχουμε στην διάθεση μας είναι:\n",
    "\n",
    "    1. Οι εικόνες __e__ του κάθε ματιού με διαστάσεις (W,H) = (60,36)\n",
    "\n",
    "\t2. __Ηead Pose__, 2d διάνυσμα γωνιών σε radians(γωνία Theta και γωνία\n",
    "Phi)\n",
    "\n",
    "\t3. __Gaze__(2d διάνυσμα επίσης σε radians) το όποιο προσπαθούμε να κάνουμε predict. Κάθε μάτι γίνεται predict __ανεξάρτητα__ από το άλλο\n",
    "\n",
    "\t4. Η γωνία __Theta__ εκφράζει την οριζόντια θέση του κεφαλιού. Για\n",
    "παράδειγμα αν το κεφάλι έχει προσανατολισμό  προς τα __δεξιά__, θα έχει\n",
    "__θετική__ τιμή, ενώ αν κοιτάει προς τα __αριστερά__, θα έχει __αρνητική__.\n",
    "\n",
    "\t5. Η γωνία __Phi__ λειτουργεί σαν την Theta, αλλά για τον κάθετο άξονα.\n",
    "Για παράδειγμα, αν το κεφάλι έχει προσανατολισμό προς τα __πάνω__, θα έχει\n",
    "__θετική τιμή__, ενώ αν κοιτάει προς τα __κάτω__, θα έχει __αρνητική__\n",
    "\n",
    "\t6. Και οι 2 αυτές γωνίες κυμαίνονται στο διάστημα [-30, +30] σε\n",
    "__μοίρες__\n",
    "\n",
    "\n",
    "* Για τον αλγόριθμο Random Forest, κάνουμε __reshape__ τις εικόνες των ματιών\n",
    "  από (W,H) = (__60,36__) σε (__15,9__) τόσο για το __training__, όσο και για το __testing__  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Υλοποίηση Αλγορίθμου\n",
    "\n",
    "\n",
    "* Για την υλοποίηση του  αλγορίθμου, βασίστηκα στην αρχική υλοποίηση του Breiman[^1], κάνοντας κάποιες αλλαγές στον τρόπο που διαλέγουμε τα __features__ κατά το split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Ομαδοποίηση των δεδομένων με βάση τα Head Poses\n",
    "\n",
    "\n",
    "* Για την υλοποίηση του  αλγορίθμου, αρχικά ομαδοποιούμε τα training samples σε __P pose clusters__, με βάση το __Head Pose__\n",
    "\n",
    "\n",
    "* Κάθε Cluster έχει ένα __κέντρο__, το οποίο αποτελείται από ένα διάνυσμα\n",
    "  (__theta, phi__)\n",
    "\n",
    "\n",
    "* Για να θεωρηθεί ένα διανύσμα (__theta, phi__) ως κέντρο ενός Cluster, θα πρέπει να <b>μην απέχει</b> απόσταση μικρότερη από <b>Χ</b> από τα ήδη υπάρχοντα κέντρα(πχ στο παρακάτω σχήμα χρησιμοποιώ __Χ=0.08__ και δημιουργούνται __106 Clusters__).\n",
    "\n",
    "\n",
    "* Όσο __μικρότερο__ το Χ, τόσο πιο __πολλά__ Clusters δημιουργούνται</br>\n",
    "\n",
    "<html><br>\n",
    "<div id=\"foto\" style=\"text-align: center;\">\n",
    "   <img src=\"centers.jpg\"  width=\"900\" alt=\"foto1\">\n",
    "        <figcaption><b>Εικόνα 1</b>:<i> Διάγραμμα που απεικονίζει τα  <b>Head Poses</b> όλων των σημείων του Training Phase. Με <b>πράσινο</b> χρώμα απεικονίζονται τα κέντρα των Clusters, ενώ με <b>μπλέ</b> χρώμα τα υπόλοιπα σημεία. Η παραπάνω εικόνα χρησιμοποιεί <b>44640</b> training δείγματα, ενώ τα <b>κέντρα</b> απέχουν μεταξύ τους απόσταση <b>μεγαλύτερη</b> των <b>0.03 radians</b>(1.718873) μοίρες)</i></figcaption>\n",
    "</div>\n",
    "</html>\n",
    "\n",
    "\n",
    "\n",
    "## Κατασκευή του δάσους μέσα από Regression Decision Trees\n",
    "\n",
    "* Χρησιμοποιώ την __bootstrap__ διαδικασία, επιλέγοντας τυχαία inputs\n",
    "\n",
    "\n",
    "* Δημιουργούμε τόσα __δέντρα__, όσα και τα __Pose Clusters__, δηλαδή P\n",
    "\n",
    "\n",
    "* Κάθε δέντρο παίρνει training data από τα __R-nearest Clusters__. Δηλαδή R Clusters\n",
    "  με τα __κοντινότερα__ Head Poses\n",
    "\n",
    "\n",
    "* Ως __error__ παίρνουμε το __μέσο gaze error__ από όλα τα regression trees.\n",
    "\n",
    "\n",
    "<div id=\"foto\" style=\"text-align: center;\">\n",
    "   <img src=\"visualization.jpeg\" width=\"500\" alt=\"foto1\">\n",
    "   <figcaption><b>Εικόνα 2</b>:<i> Παράδειγμα όπου <b>γειτονικά Clusters</b> συνεισφέρουν στην κατασκευή ενός δέντρου. Στα Clusters ανοίκουν δείγματα με <b>παρόμοια Head Poses</b></i></br></figcaption>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Πώς εκπαιδεύεται το κάθε δέντρο του δάσους\n",
    "\n",
    "\n",
    "* Σε κάθε κόμβο ενός δέντρου, προσπαθούμε να μάθουμε __συναρτήσεις__ της μορφής\n",
    "\n",
    "$$\n",
    "    f = px1 - px2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Τα px1, px2 είναι οι __Gray__ τιμές από 2 pixel της eye Image (W=15,H=9).\n",
    "\n",
    "\n",
    "* Τα __pixels__ αυτά μαθαίνονται μέσα από το training. \n",
    "\n",
    "\n",
    "* Επίσης προσπαθούμε να \"μάθουμε\" το __βέλτιστο threshold τ__ για κάθε κόμβο, όπου:\n",
    "\n",
    "    1. αν $ f < τ $, τότε το training sample κατευθύνεται στο __αριστερό__ υποδέντρο\n",
    "    \n",
    "\t2. αν $ f >= τ $, τότε κατευθύνεται στο __δεξιό__ υποδέxντρο\n",
    "\n",
    "\n",
    "* Ο αλγόριθμος με τον οποίο υπολογίζουμε ποια είναι τα __βέλτιστα pixels__ και το __βέλτιστο threshold__ για το split σε __κάθε κόμβο__ του δέντρου είναι το __minimum residual sum of squares__\n",
    "\n",
    "\n",
    "$$ \\begin{align}\n",
    " error =\\sum_{\\substack{i:f_{j}\\lt{thres}}}^{nleft}  (g_{i} - \\hat{ m_{left} } )^2 + \\sum_{\\substack{i:f_{j}\\ge{thres}}}^{nright} (g_{i} - \\hat{ m_{right} } )^2\\end{align} $$\n",
    "\n",
    "* Τα $nleft$ και $nright$ είναι ο __αριθμός__ των δειγμάτων που θα είχε κάθε υποδέντρο, σε περίπτωση που γινόταν το split με βάση τα $px1$,$px2$,$thres$\n",
    "\n",
    "\n",
    "* Τα  $\\hat{ m_{right} }$ και $\\hat{ m_{left} }$ είναι η __μέση τιμή__ των gazes που ανήκουν στο __δεξί__ και __αριστερό__ υποδέντρο\n",
    "\n",
    "\n",
    "* Διαλέγουμε τα $px1$,$px2$,$thres$ που __ελαχιστοποιούν__ το παραπάνω άθροισμα\n",
    "\n",
    "\n",
    "<html><br>\n",
    "<div id=\"foto\" style=\"text-align: center;\">\n",
    "   <img src=\"stigmiotupo.png\" width=\"800\" alt=\"foto1\">\n",
    "    <figcaption><b>Εικόνα 3:</b><i>Στιγμιότυπο υποδέντρου <b>10 δειγμάτων</b>. Ανάλογα με τις τιμές των <b>Pixel</b> του δείγματος, το τελευταίο θα οδηγηθεί σε έναν <b>τερματικό κόμβο</b>(φύλλο)</i></br></br> </figcaption>\n",
    "</div>\n",
    "</html>\n",
    "\n",
    "\n",
    "* Γενικότερα στα <b>random forests</b>(Breiman 1984, regression and classification trees), σε προβλήματα regression, προτιμάται ο αλγόριθμος των <b>resindual sum of squares</b>. Αντίθετα με τα <b>regression</b> forests, στα <b>classification</b> προβλήματα η κατασκευή των δέντρων βασίζεται σε άλλες μεθόδους όπως το <b>tree entropy/gain</b> ή το <b>Gini impurity index</b>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Ο τρόπος μάθησης των στοιχείων διαχωρισμού περιγράφεται παρακάτω:\n",
    " \n",
    "<html><br>\n",
    "<div id=\"foto\" style=\"text-align: center;\">\n",
    "   <img src=\"pseudocode.png\" alt=\"foto1\">\n",
    "    <figcaption><b>Εικόνα 4:</b><i>Στιγμιότυπο υποδέντρου <b>10 δειγμάτων</b>. Ανάλογα με τις τιμές των <b>Pixel</b> του δείγματος, το τελευταίο θα οδηγηθεί σε έναν <b>τερματικό κόμβο</b>(φύλλο)</i></br></br> </figcaption>\n",
    "</div>\n",
    "</html>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!--\n",
    "      \n",
    "                1. Για κάθε δυνατό ζευγάρι pixel(px1,px2)\n",
    "                    2. Για κάθε threshold\n",
    "                        3. Υπολόγισε το rightError= sum of squares error στο δεξί υποδέντρο  \n",
    "                        4. Υπολόγισε το leftError για το αριστερό υποδέντρο\n",
    "                        5. Error = rightError + leftError\n",
    "                        6. Αν Error < minError\n",
    "                            7. minError = Error\n",
    "                            8. minPx1 = px1\n",
    "                            9. minPx2 = px2\n",
    "                            10. minThreshold = threshold\n",
    "-->                                  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Οπότε έτσι μαθαίνουμε τα  minPx1, minPx2, minThreshold κάθε κόμβου\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Πώς γίνεται το testing\n",
    "\n",
    "\n",
    "\n",
    "* Μόλις θέλουμε να ελέγξουμε ένα testing sample, δεν το στέλνουμε σε όλα τα\n",
    "  δέντρα, αλλά στα __R-nearest δέντρα__ με βάσει το head pose\n",
    "\n",
    "\n",
    "* Τότε υπολογίζουμε το __average error__ από τα R-nearest regression δέντρα.\n",
    "\n",
    "\n",
    "* Μας ενδιαφέρει ωστόσο να γνωρίζουμε και την __τυπική απόκλιση__(standard deviation), για να βλέπουμε __πόσο κοντά__ είναι οι προβλέψεις μας στο __mean error__\n",
    "\n",
    "\n",
    "\n",
    "## Πειραματική Αξιολόγηση Αλγορίθμου\n",
    "\n",
    "\n",
    "\n",
    "* Κατά την αναλυτική αξιολόγηση του Αλγορίθμου θα πρέπει να απαντήσουμε τα εξής ερωτήματας:\n",
    "\n",
    "    1. Ποιός είναι ο βέλτιστος __αριθμός__ από __Clusters__ ή ισοδύναμα ποιά θα είναι η __μικρότερη δυνατή απόσταση__ μεταξύ 2 κέντρων\n",
    "\n",
    "    2. Ποιός είναι ο βέλτιστος __αριθμός γειτόνων__ κάθε Cluster\n",
    "\n",
    "    3.  Ποιός είναι ο βέλτιστος __αριθμός δειγμάτων__ εκπαίδευσης\n",
    "\n",
    "    4. Κατά τη διαδικασία δημιουργίας υποδέντρων σε ένα δέντρο, πόσες __μεταβλητές διαχωρισμού__ χρησιμοποιούμε?\n",
    "\n",
    "    5. Πόσο __βάθος__ πρέπει να έχει το κάθε δέντρου\n",
    "\n",
    "    6. Αν σε ένα δέντρο καταλήξουμε σε φύλλο όπου υπάρχουν  __παραπάνω από ένα__ δείγματα, πώς προσδιορίζεται η 2d-gaze του συγκεκριμένου δέντρου\n",
    "\n",
    "\n",
    "\n",
    "##### Ερώτημα 1ο: Εύρεση μικρότερης απόστασης Κέντρων/Αριθμός Clusters\n",
    "\n",
    "\n",
    "* Επειδή δεν έχουμε υπολογίσει ακόμα τον __βέλτιστο αριθμό γειτόνων__, θεωρώ αρχικά πως __R = 5__ γείτονες.\n",
    "\n",
    "\n",
    "* Επίσης, για να μειώσω τον χρόνο εκπαίδευσης, χρησιμοποιώ αρχικά __10,000 training samples__\n",
    "\n",
    "\n",
    "* Ο αριθμός των __μεταβλητών διαχωρισμού__ που θα χρησιμοποιούσαμε είναι <b>WIDTH</b> * <b>HEIGHT</b> * <b>THRESHOLD_RANGE</b> = 15 * 16 * 255. Επειδή ο αριθμός αυτός είναι υπερβολικά μεγάλος, σύμφωνα με το paper του <b>Breiman</b> αρκεί χρησιμοποιήσουμε την __τετραγωνική ρίζα__ αυτού του αριθμού\n",
    "\n",
    "\n",
    "* Τέλος, αν ένα φύλλο ενός δέντρου περιέχει __παραπάνω από ένα__ training samples, υπολογίζω απλώς τον __μέσο όρο__ των __2-d gazes__ και προκύπτει ένα 2d-gaze διάνυσμα\n",
    "\n",
    "\n",
    "* Δεν περιορίζουμε το βάθος του κάθε δέντρου\n",
    "\n",
    "\n",
    "* Με βάση τα παραπάνω, υπολογίζουμε το __mean error__ και το __standard deviation__\n",
    "\n",
    "<html><br>\n",
    "<div id=\"foto\" style=\"text-align: center;\">\n",
    "    <img src=\"graph1.jpg\" height=\"400\" width=\"600\" alt=\"foto1\">\n",
    "    <figcaption><b>Εικόνα 5:</b><i>Διάγραμμα με οριζόντιο άξονα την <b>ελάχιστη απόσταση</b> σε rad ανάμεσα σε 2 κέντρα των γειτονικών Cluster συναρτήσει του <b>μέσου σφάλματος</b> και της <b>τυπικής απόκλισης</b>. Για απόσταση <b>d=0.05</b> rad παρατηρούμε το ελάχιστο μέσο σφάλμα. H τυπική απόκλιση είναι <b>υψηλή</b>(=5.31 μοίρες)</i></br></br> </figcaption>\n",
    "</div>\n",
    "</html>\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "* Από το γράφημα παρατηρούμε πως το <b>mean error</b> γίνεται ελάχιστο για όταν η minimum απόσταση ανάμεσα στα κέντρα είναι <b>0.05 degrees</b>(οριζόντια + κάθετα)\n",
    "\n",
    "\n",
    "* Ωστόσο η <b>τυπική απόκλιση</b> είναι αρκετά μεγάλη(5.38 μοίρες), πράγμα που σημαίνει πως οι προβλέψεις έχουν αρκετή <b>διαφορά</b> μεταξύ τους ως προς τον μέσο όρο\n",
    "\n",
    "\n",
    "* Κρατάμε ως απόσταση το 0.05 μεταξύ των κεντρών. Θέτοντας την απόσταση των κεντρών(των Cluster) 0.05, για 10,000 δείγματα εκπαίδευσης προκύπτουν <b>238 κέντρα</b> \n",
    "\n",
    "\n",
    "##### Ερώτημα 2ο: Βέλτιστος Αριθμός γειτονικών Cluster\n",
    "\n",
    "\n",
    "\n",
    "* Κρατάμε ως δεδομένα την <b>minimum απόσταση</b> μεταξύ 2 κέντρων(=<b>0.05</b> rads) που βρήκαμε στο προηγούμενο ερώτημα και συνεχίζουμε τις μετρήσεις, αναζητώντας τον ιδανικό <b>αριθμό γειτονικών Cluster</b> που θα συνεισφέρουν στην εκπαίδευση ενός δέντρου.\n",
    "\n",
    "\n",
    "* Όπως και στο προηγούμενο ερώτημα, ο αριθμός των δειγμάτων εκπαίδευσης παραμένει <b>10,000</b>\n",
    "\n",
    "\n",
    "<html><br>\n",
    "<div id=\"foto\" style=\"text-align: center;\">\n",
    "    <img src=\"graph2.jpg\" height=\"400\" width=\"600\" alt=\"foto1\">\n",
    "    <figcaption><b>Εικόνα 6:</b><i>Διάγραμμα με οριζόντιο άξονα τον <b>αριθμό γειτόνων</b> που συνεισφέρουν στην εκπαίδευση ενός δέντρου συναρτήσει του <b>μέσου σφάλματος</b> και της <b>τυπικής απόκλισης</b>. Το ελάχιστο μέσο σφάλμα παρατηρείται για <b>R = 30</b>. Από το σημείο αυτό και μετά η μείωση θεωρείται αμελητέα. H τυπική απόκλιση εξακολουθεί να παραμένει αρκετά <b>υψηλή</b>(περίπου 5 μοίρες)</i></br></br> </figcaption>\n",
    "</div>\n",
    "\n",
    "\n",
    "* Παρατηρούμε πως η <b>αύξηση</b> του αριθμού των <b>γειτόνων</b>(μέχρι ένα σημείο) προκαλεί <b>μείωση</b> του <b>σφάλματος</b>\n",
    "\n",
    "\n",
    "* Αυτό συμβαίνει διότι καθώς <b>αυξάνουμε</b> τον αριθμό γειτόνων, <b>περισσότερα</b> δέντρα συνεισφέρουν στο τελικό αποτέλεσμα που θέλουμε να προβλέψουμε\n",
    "\n",
    "\n",
    "* Έτσι, παίρνοντας ως αποτέλεσμα την <b>μέση</b> πρόβλεψη όλων των δέντρων, <b>μικραίνει</b> η πιθανότητα να έχουμε <b>λανθασμένες</b> προβλέψεις\n",
    "\n",
    "\n",
    "* Αυτό είναι το σημείο που <b>υπερτερούν</b> τα random forests σε σχέση με τα decision trees. Τα <b>decision trees</b> από την φύση τους μπορούν <b>εύκολα</b> να κάνουν μία <b>λάθος</b> πρόβλεψη. Στα <b>random forests</b>, αν ένα δέντρο κάνει μια \"κακή πρόβλεψη\", τα υπόλοιπα δέντρα είναι σε θέση να <b>διορθώσουν</b> την πρόβλεψη αυτή, αφού παίρνουμε τον <b>μέσο όρο</b> όλων των δέντρων\n",
    "\n",
    "\n",
    "\n",
    "##### Ερώτημα 3ο: Ποιός είναι ο βέλτιστος αριθμός δειγμάτων εκπαίδευσης\n",
    "\n",
    "\n",
    "* Θεωρώντας δεδομένο τον <b>αριθμό γειτόνων</b>(R=5) και την <b>ελάχιστη απόσταση</b> των κέντρων των Clusters(dist=0.05), προσπαθούμε να βρούμε τον βέλτιστο <b>αριθμό δειγμάτων</b> εκπαίδευσης.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<html><br>\n",
    "<div id=\"foto\" style=\"text-align: center;\">\n",
    "    <img src=\"graph3.jpg\" height=\"400\" width=\"600\" alt=\"foto1\">\n",
    "    <figcaption><b>Εικόνα 6:</b><i>Διάγραμμα με οριζόντιο άξονα τον <b>αριθμό δειγμάτων εκπαίδευσης</b> συναρτήσει του <b>μέσου σφάλματος</b> και της <b>τυπικής απόκλισης</b>. Το μέσο σφάλμα <b>συγκλίνει</b> στην τιμή <b>6.49</b> μοίρες, ενώ η τυπική απόκλιση παραμένει γύρω στις <b>4.7</b> μοίρες</i></br></br> </figcaption>\n",
    "</div>\n",
    "</html>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Οι λόγοι για τους οποίους το σφάλμα <b>συγκλίνει</b> αντί να <b>μειώνεται</b> είναι παρόμοιοι με αυτούς των <b>δέντρων αποφάσεων</b> \n",
    "\n",
    "\n",
    "    * Σύμφωνα με τον <b>Breiman</b>, τα random forests <b>αποφεύγουν</b> το <b>overfitting</b> καθώς αυξάνεται το <b>training sample</b>\n",
    "\n",
    "To avoid over-fitting in random forest, the main thing you need to do is optimize a tuning parameter that governs the number of features that are randomly chosen to grow each tree from the bootstrapped data. Typically, you do this via k-fold cross-validation, where k∈{5,10}, and choose the tuning parameter that minimizes test sample prediction error. In addition, growing a larger forest will improve predictive accuracy, although there are usually diminishing returns once you get up to several hundreds of trees.\n",
    "\n",
    "* Και στις 2 περιπτώσεις, παρατηρείται το overfitting(παραπάνω δεδομένα εκπαίδευσης\n",
    "\n",
    "\n",
    "* Οπότε παίρνουμε ως ολικό <b>μέσο</b> σφάλμα <b>6.49247</b> μοίρες με <b>τυπική απόκλιση</b> ως προς αυτό <b>4.70</b> μοίρες\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Ερώτημα 4ο: Εύρεση αριθμού μεταβλητών διαχωρισμού(split features)\n",
    "\n",
    "\n",
    "\n",
    "* <b>Μεταβλητές διαχωρισμού</b>(split features) είναι μεταβλητές οι οποίες καθορίζουν <b>πώς</b> θα γίνει το split(διαχωρισμός training samples) σε κάθε κόμβο του δέντρου. \n",
    "\n",
    "\n",
    "* Στο συγκεκριμένο πρόβλημα, χρησιμοποιούμε τις εξής <b>μεταβλητές διαχωρισμού</b>:\n",
    "\n",
    "    1. Τις <b>συντεταγμένες</b>(height,width) του <b>pixel 1</b>\n",
    "    \n",
    "\t2. Τις <b>συντεταγμένες</b>(height,width) του <b>pixel 2</b>\n",
    "    \n",
    "    3. Την <b>απόσταση</b>(threshold) ανάμεσα στις <b>gray</b> τιμές(0 -> 255 εύρος) αυτών των 2 pixel\n",
    "\n",
    "\n",
    "* Υπάρχουν <b>height*width</b> πιθανές τιμές που μπορούν να πάρουν  η 1η και η 2η μεταβλητή \n",
    "\n",
    "\n",
    "* Η μεταβλητή <b>threshold</b> έχει εύρος τιμών(thres_range) από <b>0</b> μέχρι <b>50</b>(αυθαίρετο το 50)\n",
    "\n",
    "\n",
    "* Κατά την διαδικασία της εκμάθησης, είπαμε πως προσπαθούμε να μάθουμε τί <b>τιμή</b> θα έχουν αυτές οι μεταβλητές σε κάθε <b>μή-τερματικό</b> κόμβο του κάθε δέντρου \n",
    "\n",
    "\n",
    "* Ωστόσο, υπολογιστικά θα ήταν δύσκολο να δοκιμάσω  $thresholdRange * (height*width)^2 = 50*(9*15)^2 = 911,250$ <b>διαφορετικές</b> παραμέτρους, ώστε να τις χρησιμοποιήσω στον τύπο για τον υπολογισμό του minimum square error\n",
    "\n",
    "\n",
    "* Αυτό λύνεται σύμφωνα με τον <b>Breiman</b>(2001), o oποίος αναφέρει πως δεν χρειάζεται να δοκιμάσουμε <b>όλους</b> τους συνδιασμούς των παραμέτρων. Αρκεί να χρησιμοποιήσουμε την <b>τετραγωνική ρίζα</b> αυτών, επιλέγοντας <b>τυχαίους</b> συνδιασμούς(στην <b>εικόνα 4</b>, o αλγόριθμος ανταποκρίνεται για τους <b>911,250</b> συνδιασμούς. Στην πράξη όμως χρησιμοποιούμε την <b>τετραγωνική ρίζα</b> αυτών) \n",
    "\n",
    "\n",
    "\n",
    "* Πράγματι, παρόλο που δεν πραγματοποιούμε όλους τους συνδιασμούς, η απόδοση του αλγορίθμου παραμένει η <b>υψηλότερη</b> όταν χρησιμοποιούμε την τετραγωνική ρίζα των συνδιασμών\n",
    "\n",
    "\n",
    "\n",
    "##### Ερώτημα 5ο: Βέλτιστο βάθος κάθε δέντρου\n",
    "\n",
    "\n",
    "* Σύμφωνα με τον <b>Breiman</b>(2001), το βάθος κάθε δέντρου δεν θα πρέπει να περιορίζεται.πρέπει να είναι\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Πιθανές βελτιώσεις του αλγορίθμου\n",
    "\n",
    "\n",
    "#####   1) Μείωση του αριθμού των features\n",
    "\n",
    "\n",
    "* Όπως αναφέραμε και στο <b>ερώτημα 4</b>, ο αριθμός των features που χρησιμοποιούμε είναι αρκετά <b>μεγάλος)</b>(=911,250). \n",
    "\n",
    "\n",
    "* Αν και ο Breiman(2001) θεωρεί πως η εισαγωγή της <b>τυχαιότητας</b> κατά την επιλογή των features σε συνδιασμό με τον <b>μεγάλο αριθμό δέντρων</b>(γειτόνων στο δικό μας πρόβλημα) μπορεί να <b>εξαλείψει</b> το πρόβλημα του μεγάλου αριθμού από features, θα μπορούσαμε ωστόσο πειραματικά να εφαρμόσουμε αλγορίθμους που <b>μειώνουν</b> τον αριθμό των <b>features</b>(dimensionality reduction) πριν τρέξουμε τον αλγόριθμο μας(πχ. PCA, LDA) και να ελέγξουμε κατά πόσο οι αλγόριθμοι αυτοί μειώνουν το <b>ολικό error</b>. \n",
    "\n",
    "\n",
    "* Με αυτόν τον τρόπο, θα μπορούσαμε κατά την κατασκευή ενός μη-τερματικού κόμβου να κάνουμε απαλοιφή κάποιων features ώστε να επικεντρωθούμε σε σημαντικά features\n",
    "\n",
    "\n",
    "* Υπάρχει ωστόσο ο κίνδυνος να δημιουργούνται κατά το training όμοια δέντρα, πράγμα που αφαιρεί το νόημα του αλγορίθμου. Αυτό συμβαίνει διότι με λιγότερα features είναι πιθανότερο να υπάρχουν όμοια δέντρα\n",
    "\n",
    "\n",
    "#####    2) Κάθε πρόβλεψη ενός δέντρου έχει έναν συντελεστή \"αυτοπεποίθησης\"\n",
    "\n",
    "\n",
    "* Η τεχνική αυτή παρουσιάζεται στο [^4], όπου κάθε <b>πρόβλεψη</b> ενός μεμονωμένου δέντρου, συνοδεύεται από έναν συντελεστή όμοιο με την <b>τυπική απόκλιση</b>\n",
    "\n",
    "\n",
    "* Αν στο <b>τερματικό φύλλο</b> ενός δέντρου ανήκουν <b>παραπάνω από 1</b> training samples, υπολογίζουμε την <b>τυπική απόκλιση</b> των training samples αυτών ως προς την <b>μέση τιμή</b>\n",
    "\n",
    "\n",
    "* Αν η τιμή της τυπικής απόκλισης <b>ξεπερνά</b> μια <b>προκαθορισμένη</b> τιμή, τότε η πρόβλεψη θεωρείται <b>αναξιόπιστη</b> και το δάσος <b>απορρίπτει</b> την πρόβλεψη αυτού του δέντρου. \n",
    "\n",
    "\n",
    "* Ο <b>τελικός</b> μέσος όρος στην περίπτωση αυτή υπολογίζεται <b>χωρίς</b> να λαμβάνουμε υπ'όψη το δέντρο αυτό\n",
    "\n",
    "\n",
    "* Με αυτόν τον τρόπο, <b>απορρίπτουμε</b> προβλέψεις οι οποίες είναι <b>αμφίβολες</b>, καθώς δεν αντικατοπτρίζεται ο μέσος όρος από τα training samples\n",
    "\n",
    "\n",
    "#####   3) Χρήση κάποιας συνάρτησης αντί του μέσου όρου στα φύλλα των δέντρων\n",
    "\n",
    "\n",
    "* Στις περιπτώσεις όπου το φύλλο ενός δέντρου περιέχει παραπάνω από ένα training samples, θα μπορούσαμε να χρησιμοποιήσουμε για τον προσδιορισμό του τελικού 2d-gaze διανύσματος κάποια συνάρτηση, αντί για τον υπολογισμού του μέσου gaze\n",
    "\n",
    "\n",
    "* Ανάλογα με την <b>κατανομή</b> των δεδομένων, \n",
    "\n",
    "\n",
    "\n",
    "## Aναφορές σε βιβλιογραφίες/δημοσιεύσεις\n",
    "\n",
    "\n",
    "[^1]: Breiman, L., Friedman, J.,Olshen, R., and Stone, C. [1984] Classification and Regression Trees,  Wadsworth\n",
    "[^2]: Y. Sugano, Y. Matsushita, and Y. Sato. [Learning-by-synthesis for appearance-based 3d gaze estimation.\n",
    "[^3]: Z. Zhang, Y.Sugano, M.Fritz, A. Bulling [2015] Appearance-Based Gaze Estimation in the Wild\n",
    "[^4]: M. Dantone, J. Gall, G. Fanelli, L. Van Gool:  Real-time  facial feature detection using conditional regression forests.\n",
    "\n",
    "\n",
    "</div>\n",
    "</body>\n",
    "<!--\n",
    "</style>  \n",
    "-->    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "numOfNeighbors=['10', '20', '30', '40', '50', '60', '70', '80']\n",
    "mean_error= [7.31, 6.66583, 6.5842, 6.5562, 6.57644, 6.54578, 6.50432, 6.49247]\n",
    "std_error=  [5.42, 4.73184,  4.69651, 4.7532, 4.78703, 4.76607, 4.7156,4.70662]\n",
    "width=0.5\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(r'Number Of $\\bf{{{a}}}$ $\\bf{{{b}}}$(in thousands)'.format(a='training', b='samples') )\n",
    "plt.ylabel('error(degrees)')\n",
    "#plt.title('Mean error and standar deviation for 5 neighbours and 10,000 training samples')\n",
    "plt.title(r'Errors for $\\bf{{{a}}}$ rads center distance and $\\bf{{{b}}}$ cluster neighbours'.format(a='0.05', b='R=5' ) )\n",
    "axes = plt.gca()\n",
    "#axes.set_xlim([0,45])\n",
    "axes.set_ylim([4.0,8.0])\n",
    "\n",
    "plt.xticks(np.arange(len(numOfNeighbors)),numOfNeighbors)\n",
    "plt.bar(np.arange(len(numOfNeighbors)), mean_error, width, label='mean error')\n",
    "plt.bar(np.arange(len(numOfNeighbors)), std_error, width, label='standar deviation')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('graph3.jpg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
